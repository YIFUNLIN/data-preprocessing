{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f0e33e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:\\Users\\linnn\\Desktop\\电子资源-零基础学机器学习\\第4课 逻辑回归\\教学用例1 心脏病\\数据集\\heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4422a5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()          #輸入某欄位名稱，使用value_counts()方法，可顯示各類別的數目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02283d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#以年齡+最大心跳作為輸入，查看分類結果散點圖\n",
    "\n",
    "#有心臟病\n",
    "plt.scatter(x = df.age[df.target==1],      #設定條件，年齡但要符合target=1(有心臟病)的人，才會納入\n",
    "           y = df.thalach[df.target==1],c = 'red')\n",
    "\n",
    "#無心臟病\n",
    "plt.scatter(x = df.age[df.target==0],\n",
    "           y = df.thalach[df.target==0],marker='^')\n",
    "\n",
    "plt.legend(['Disease','No Disease'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Heart Rate')\n",
    "plt.show()                 #顯示出心跳愈高，患心臟病的可能性就愈大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d4583b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target'],axis=1)          #Dataframe\n",
    "y = df.target.values    #加.values可將資料型態從series轉成ndarray，因為series無法reshpae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "275fae38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e84013ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e54675f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d74e6d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "張量X的形狀: (303, 13)\n",
      "張量y的形狀: (303, 1)\n"
     ]
    }
   ],
   "source": [
    "print('張量X的形狀:',X.shape)\n",
    "print('張量y的形狀:',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3e7524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split         #將資料作拆分\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9ef15d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "185   44    1   0       112   290    0        0      153      0      0.0   \n",
       "118   46    0   1       105   204    0        1      172      0      0.0   \n",
       "189   41    1   0       110   172    0        0      158      0      0.0   \n",
       "166   67    1   0       120   229    0        0      129      1      2.6   \n",
       "171   48    1   1       110   229    0        1      168      0      1.0   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "263   63    0   0       108   269    0        1      169      1      1.8   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "242   64    1   0       145   212    0        0      132      0      2.0   \n",
       "272   67    1   0       120   237    0        1       71      0      1.0   \n",
       "180   55    1   0       132   353    0        1      132      1      1.2   \n",
       "\n",
       "     slope  ca  thal  \n",
       "185      2   1     2  \n",
       "118      2   0     2  \n",
       "189      2   0     3  \n",
       "166      1   2     3  \n",
       "171      0   0     3  \n",
       "..     ...  ..   ...  \n",
       "263      1   2     2  \n",
       "298      1   0     3  \n",
       "242      1   2     1  \n",
       "272      1   0     2  \n",
       "180      1   1     3  \n",
       "\n",
       "[242 rows x 13 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d004bf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "228   59    1   3       170   288    0        0      159      0      0.2   \n",
       "274   47    1   0       110   275    0        0      118      1      1.0   \n",
       "227   35    1   0       120   198    0        1      130      1      1.6   \n",
       "140   51    0   2       120   295    0        0      157      0      0.6   \n",
       "149   42    1   2       130   180    0        1      150      0      0.0   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "213   61    0   0       145   307    0        0      146      1      1.0   \n",
       "291   58    1   0       114   318    0        2      140      0      4.4   \n",
       "206   59    1   0       110   239    0        0      142      1      1.2   \n",
       "237   60    1   0       140   293    0        0      170      0      1.2   \n",
       "219   48    1   0       130   256    1        0      150      1      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "228      1   0     3  \n",
       "274      1   1     2  \n",
       "227      1   0     3  \n",
       "140      2   0     2  \n",
       "149      2   0     2  \n",
       "..     ...  ..   ...  \n",
       "213      1   0     3  \n",
       "291      0   3     1  \n",
       "206      1   1     3  \n",
       "237      1   2     3  \n",
       "219      2   2     3  \n",
       "\n",
       "[61 rows x 13 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a4ae0988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#資料特徵縮放，使資料皆落在[0,1]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#對資料壓縮器進行兩次呼叫\n",
    "X_train = scaler.fit_transform(X_train)     #先擬和再應用      \n",
    "X_test = scaler.transform(X_test)       #直接應用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e5f768a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3125    , 1.        , 0.        , ..., 1.        , 0.25      ,\n",
       "        0.66666667],\n",
       "       [0.35416667, 0.        , 0.33333333, ..., 1.        , 0.        ,\n",
       "        0.66666667],\n",
       "       [0.25      , 1.        , 0.        , ..., 1.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.72916667, 1.        , 0.        , ..., 0.5       , 0.5       ,\n",
       "        0.33333333],\n",
       "       [0.79166667, 1.        , 0.        , ..., 0.5       , 0.        ,\n",
       "        0.66666667],\n",
       "       [0.54166667, 1.        , 0.        , ..., 0.5       , 0.25      ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1ce6bff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.625     , 1.        , 1.        , 0.71698113, 0.36986301,\n",
       "        0.        , 0.        , 0.67175573, 0.        , 0.03571429,\n",
       "        0.5       , 0.        , 1.        ],\n",
       "       [0.375     , 1.        , 0.        , 0.1509434 , 0.34018265,\n",
       "        0.        , 0.        , 0.35877863, 1.        , 0.17857143,\n",
       "        0.5       , 0.25      , 0.66666667],\n",
       "       [0.125     , 1.        , 0.        , 0.24528302, 0.16438356,\n",
       "        0.        , 0.5       , 0.45038168, 1.        , 0.28571429,\n",
       "        0.5       , 0.        , 1.        ],\n",
       "       [0.45833333, 0.        , 0.66666667, 0.24528302, 0.38584475,\n",
       "        0.        , 0.        , 0.65648855, 0.        , 0.10714286,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.27083333, 1.        , 0.66666667, 0.33962264, 0.12328767,\n",
       "        0.        , 0.5       , 0.60305344, 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.8125    , 1.        , 0.66666667, 0.81132075, 0.33789954,\n",
       "        1.        , 0.        , 0.60305344, 1.        , 0.28571429,\n",
       "        0.5       , 0.        , 1.        ],\n",
       "       [0.47916667, 1.        , 0.33333333, 0.24528302, 0.4543379 ,\n",
       "        0.        , 0.5       , 0.77099237, 0.        , 0.03571429,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.8125    , 1.        , 0.66666667, 0.22641509, 0.34474886,\n",
       "        0.        , 0.5       , 0.61068702, 0.        , 0.17857143,\n",
       "        1.        , 0.25      , 1.        ],\n",
       "       [0.35416667, 1.        , 0.66666667, 0.52830189, 0.23972603,\n",
       "        0.        , 0.5       , 0.58015267, 0.        , 0.64285714,\n",
       "        0.5       , 0.        , 0.66666667],\n",
       "       [0.83333333, 1.        , 1.        , 0.62264151, 0.24657534,\n",
       "        1.        , 0.        , 0.45801527, 0.        , 0.01785714,\n",
       "        0.5       , 0.25      , 0.66666667],\n",
       "       [0.375     , 1.        , 0.66666667, 0.13207547, 0.26712329,\n",
       "        0.        , 0.5       , 0.61832061, 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.52083333, 1.        , 0.33333333, 0.9245283 , 0.35844749,\n",
       "        0.        , 0.        , 0.94656489, 0.        , 0.        ,\n",
       "        1.        , 0.25      , 1.        ],\n",
       "       [0.66666667, 1.        , 0.        , 0.43396226, 0.18493151,\n",
       "        0.        , 0.        , 0.51145038, 1.        , 0.33928571,\n",
       "        1.        , 0.25      , 1.        ],\n",
       "       [0.125     , 1.        , 0.        , 0.30188679, 0.35616438,\n",
       "        0.        , 0.        , 0.64885496, 1.        , 0.        ,\n",
       "        1.        , 0.        , 1.        ],\n",
       "       [0.52083333, 1.        , 0.        , 0.26415094, 0.3652968 ,\n",
       "        0.        , 0.        , 0.34351145, 1.        , 0.57142857,\n",
       "        0.5       , 0.5       , 0.66666667],\n",
       "       [0.75      , 1.        , 0.        , 0.24528302, 0.11643836,\n",
       "        0.        , 0.5       , 0.52671756, 0.        , 0.07142857,\n",
       "        1.        , 0.        , 1.        ],\n",
       "       [0.6875    , 0.        , 0.        , 0.62264151, 0.08675799,\n",
       "        0.        , 0.        , 0.5648855 , 0.        , 1.10714286,\n",
       "        0.        , 0.75      , 1.        ],\n",
       "       [0.58333333, 0.        , 0.        , 0.24528302, 0.52054795,\n",
       "        0.        , 0.5       , 0.70229008, 1.        , 0.10714286,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.25      , 0.        , 0.33333333, 0.30188679, 0.4109589 ,\n",
       "        0.        , 0.5       , 0.70229008, 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.58333333, 1.        , 0.66666667, 0.52830189, 0.09589041,\n",
       "        0.        , 0.5       , 0.78625954, 0.        , 0.28571429,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.41666667, 1.        , 0.33333333, 0.33962264, 0.3196347 ,\n",
       "        0.        , 0.5       , 0.76335878, 0.        , 0.10714286,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.3125    , 1.        , 0.66666667, 0.43396226, 0.24885845,\n",
       "        0.        , 0.        , 0.83206107, 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.5625    , 0.        , 0.        , 0.37735849, 0.64611872,\n",
       "        0.        , 0.        , 0.60305344, 1.        , 0.33928571,\n",
       "        0.5       , 0.5       , 1.        ],\n",
       "       [0.3125    , 1.        , 0.66666667, 0.24528302, 0.2283105 ,\n",
       "        0.        , 0.5       , 0.7480916 , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.625     , 1.        , 0.        , 0.71698113, 0.456621  ,\n",
       "        0.        , 0.        , 0.52671756, 1.        , 0.60714286,\n",
       "        0.        , 0.        , 1.        ],\n",
       "       [0.35416667, 0.        , 0.66666667, 0.45283019, 0.11643836,\n",
       "        0.        , 0.        , 0.67938931, 1.        , 0.25      ,\n",
       "        0.        , 0.        , 0.66666667],\n",
       "       [0.54166667, 1.        , 0.        , 0.62264151, 0.37214612,\n",
       "        0.        , 0.        , 0.5648855 , 1.        , 0.14285714,\n",
       "        0.5       , 0.25      , 1.        ],\n",
       "       [0.5625    , 1.        , 0.        , 0.35849057, 0.13242009,\n",
       "        0.        , 0.        , 0.25954198, 1.        , 0.375     ,\n",
       "        0.5       , 0.25      , 0.33333333],\n",
       "       [0.4375    , 0.        , 0.        , 0.1509434 , 0.29223744,\n",
       "        0.        , 0.        , 0.67175573, 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.60416667, 1.        , 0.33333333, 0.29245283, 0.21461187,\n",
       "        0.        , 0.5       , 0.55725191, 0.        , 0.07142857,\n",
       "        0.5       , 1.        , 1.        ],\n",
       "       [0.33333333, 1.        , 0.        , 0.19811321, 0.30593607,\n",
       "        0.        , 0.        , 0.87022901, 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.60416667, 0.        , 0.        , 0.71698113, 0.2260274 ,\n",
       "        1.        , 0.        , 0.57251908, 1.        , 0.5       ,\n",
       "        0.5       , 0.5       , 0.33333333],\n",
       "       [0.60416667, 0.        , 0.66666667, 0.24528302, 0.48858447,\n",
       "        0.        , 0.5       , 0.77099237, 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.25      , 1.        , 0.33333333, 0.24528302, 0.07077626,\n",
       "        0.        , 0.5       , 0.84732824, 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.47916667, 0.        , 0.66666667, 0.39622642, 0.15981735,\n",
       "        0.        , 0.        , 0.7480916 , 0.        , 0.01785714,\n",
       "        0.5       , 0.        , 0.66666667],\n",
       "       [0.66666667, 0.        , 0.        , 0.33962264, 0.46575342,\n",
       "        0.        , 0.        , 0.7480916 , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.41666667, 1.        , 0.66666667, 0.24528302, 0.14155251,\n",
       "        0.        , 0.5       , 0.51908397, 0.        , 0.35714286,\n",
       "        0.5       , 0.75      , 1.        ],\n",
       "       [0.54166667, 0.        , 0.33333333, 0.35849057, 0.49315068,\n",
       "        0.        , 0.5       , 0.72519084, 0.        , 0.21428571,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.60416667, 1.        , 0.33333333, 0.24528302, 0.36073059,\n",
       "        0.        , 0.        , 0.67938931, 0.        , 0.32142857,\n",
       "        0.5       , 0.        , 0.66666667],\n",
       "       [0.3125    , 0.        , 0.66666667, 0.13207547, 0.03424658,\n",
       "        0.        , 0.5       , 0.79389313, 0.        , 0.10714286,\n",
       "        0.5       , 0.        , 0.66666667],\n",
       "       [0.22916667, 1.        , 0.        , 0.1509434 , 0.09360731,\n",
       "        0.        , 0.        , 0.32824427, 1.        , 0.35714286,\n",
       "        0.5       , 0.        , 1.        ],\n",
       "       [0.64583333, 1.        , 0.        , 0.33962264, 0.28995434,\n",
       "        0.        , 0.5       , 0.55725191, 1.        , 0.25      ,\n",
       "        1.        , 0.25      , 1.        ],\n",
       "       [0.52083333, 1.        , 0.66666667, 0.29245283, 0.33561644,\n",
       "        0.        , 0.        , 0.61832061, 0.        , 0.08928571,\n",
       "        0.        , 0.25      , 0.66666667],\n",
       "       [0.33333333, 1.        , 0.33333333, 0.32075472, 0.41552511,\n",
       "        0.        , 0.        , 0.75572519, 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.4375    , 1.        , 0.        , 0.52830189, 0.26712329,\n",
       "        0.        , 0.        , 0.4351145 , 0.        , 0.46428571,\n",
       "        0.5       , 0.        , 1.        ],\n",
       "       [0.33333333, 1.        , 1.        , 0.1509434 , 0.31506849,\n",
       "        0.        , 0.5       , 0.46564885, 0.        , 0.21428571,\n",
       "        0.5       , 0.        , 1.        ],\n",
       "       [0.47916667, 1.        , 0.66666667, 0.73584906, 0.16666667,\n",
       "        1.        , 0.5       , 0.69465649, 0.        , 0.08928571,\n",
       "        1.        , 0.        , 1.        ],\n",
       "       [0.3125    , 1.        , 0.33333333, 0.24528302, 0.31278539,\n",
       "        0.        , 0.5       , 0.77862595, 0.        , 0.        ,\n",
       "        1.        , 0.        , 1.        ],\n",
       "       [0.5       , 0.        , 0.        , 0.33962264, 0.31506849,\n",
       "        0.        , 0.        , 0.54961832, 0.        , 0.07142857,\n",
       "        0.5       , 0.        , 0.66666667],\n",
       "       [0.52083333, 1.        , 0.        , 0.1509434 , 0.25799087,\n",
       "        0.        , 0.5       , 0.41984733, 1.        , 0.5       ,\n",
       "        0.5       , 0.25      , 1.        ],\n",
       "       [0.66666667, 1.        , 0.        , 0.50943396, 0.17579909,\n",
       "        0.        , 0.5       , 0.6870229 , 0.        , 0.        ,\n",
       "        1.        , 0.25      , 1.        ],\n",
       "       [0.75      , 1.        , 0.        , 0.38679245, 0.29223744,\n",
       "        0.        , 0.        , 0.42748092, 0.        , 0.5       ,\n",
       "        0.5       , 0.25      , 1.        ],\n",
       "       [0.47916667, 1.        , 1.        , 0.22641509, 0.1369863 ,\n",
       "        0.        , 0.        , 0.90839695, 0.        , 0.        ,\n",
       "        0.5       , 0.        , 0.33333333],\n",
       "       [0.125     , 1.        , 0.33333333, 0.26415094, 0.15068493,\n",
       "        0.        , 0.5       , 0.78625954, 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.4375    , 0.        , 0.33333333, 0.24528302, 0.26940639,\n",
       "        0.        , 0.5       , 0.69465649, 0.        , 0.19642857,\n",
       "        1.        , 0.        , 0.66666667],\n",
       "       [0.4375    , 1.        , 0.        , 0.47169811, 0.16894977,\n",
       "        0.        , 0.        , 0.41984733, 1.        , 0.16071429,\n",
       "        0.5       , 0.        , 1.        ],\n",
       "       [0.66666667, 0.        , 0.        , 0.48113208, 0.41324201,\n",
       "        0.        , 0.        , 0.57251908, 1.        , 0.17857143,\n",
       "        0.5       , 0.        , 1.        ],\n",
       "       [0.60416667, 1.        , 0.        , 0.18867925, 0.43835616,\n",
       "        0.        , 1.        , 0.52671756, 0.        , 0.78571429,\n",
       "        0.        , 0.75      , 0.33333333],\n",
       "       [0.625     , 1.        , 0.        , 0.1509434 , 0.25799087,\n",
       "        0.        , 0.        , 0.54198473, 1.        , 0.21428571,\n",
       "        0.5       , 0.25      , 1.        ],\n",
       "       [0.64583333, 1.        , 0.        , 0.43396226, 0.38127854,\n",
       "        0.        , 0.        , 0.75572519, 0.        , 0.21428571,\n",
       "        0.5       , 0.5       , 1.        ],\n",
       "       [0.39583333, 1.        , 0.        , 0.33962264, 0.29680365,\n",
       "        1.        , 0.        , 0.60305344, 1.        , 0.        ,\n",
       "        1.        , 0.5       , 1.        ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "30b16414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    y_hat = 1 / (1 + np.exp(-z))      #logistic function\n",
    "    return y_hat\n",
    "\n",
    "def loss_function(X,y,w,b):\n",
    "    y_hat = sigmoid(np.dot(X,w)+b)    #用Sigmoid函數 進行邏輯轉換生成y'\n",
    "    loss = -((y * np.log(y_hat) + (1-y) * np.log(1-y_hat)))   #計算損失 (預測值到真實值的誤差)\n",
    "    cost = np.sum(loss) / X.shape[0]         #將所有的樣本誤差取平均值。  X.shape[0]=303 ，matrix.shape[0]表示列數 , 1表示行數\n",
    "    return cost                       #回傳整個資料集的平均損失\n",
    "\n",
    "def gradient_descent(X,y,w,b,lr,iter):\n",
    "    l_history = np.zeros(iter)      #初始化紀錄梯度下降過程中 誤差值(損失)的array\n",
    "    w_history = np.zeros((iter,w.shape[0],w.shape[1]))       #初始化紀錄梯度下降過程中 weight的array\n",
    "    b_history = np.zeros(iter)      #初始化紀錄梯度下降過程中 bias的array\n",
    "    for i in range(iter):\n",
    "        y_hat = sigmoid(np.dot(X,w) + b )\n",
    "        loss = -(y * np.log(y_hat) + (1-y) * np.log(1-y_hat))\n",
    "        derivative_w = np.dot(X.T,(y_hat - y)) / X.shape[0]       #內積\n",
    "        derivative_b = np.sum(y_hat - y) / X.shape[0]\n",
    "        w = w - lr * derivative_w\n",
    "        b = b - lr * derivative_b\n",
    "        l_history[i] = loss_function(X,y,w,b)        #梯度下降過程中的損失\n",
    "        print('輪次',i+1,'當前輪訓練集損失:',l_history[i])\n",
    "        w_history[i] = w              #紀錄梯度下降過程中的權重\n",
    "        b_history[i] = b              #紀錄梯度下降過程中的偏置\n",
    "    return l_history,w_history,b_history \n",
    "\n",
    "def predict(X,w,b):\n",
    "    z = np.dot(X,w) + b     #線性函數  z = wX + b\n",
    "    y_hat = sigmoid(z)      #邏輯函數轉換\n",
    "    y_pred = np.zeros((y_hat.shape[0],1))    #初始化預測結果變數 \n",
    "    for i in range(y_hat.shape[0]):\n",
    "        if y_hat[i,0] < 0.5:\n",
    "            y_pred[i,0] = 0              #把原先機率值y_hat 轉成 0和1 的分類\n",
    "        else:\n",
    "            y_pred[i,0] = 1\n",
    "    return y_pred           #回傳預測分類的結果\n",
    "\n",
    "def logistic_regression(X,y,w,b,lr,iter):       #定義邏輯回歸模型\n",
    "    l_history,w_history,b_history = gradient_descent(X,y,w,b,lr,iter)\n",
    "    #Gradient descent\n",
    "    print('訓練最終損失:',l_history[-1])\n",
    "    y_pred = predict(X,w_history[-1],b_history[-1])       #進行預測。呼叫先前定義的predict()\n",
    "    training_acc = 100 - np.mean(np.abs(y_pred - y_train)) * 100     #計算準確率\n",
    "    print('Logistic regression training accuracy: {:.2f}%' .format(training_acc))\n",
    "    return l_history,w_history,b_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "788cb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = X.shape[1]     #行的數目\n",
    "weight = np.full((dimension,1),0.1)\n",
    "bias = 0\n",
    "alpha = 1\n",
    "iterations = 500      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "087c581f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 1 當前輪訓練集損失: 0.6683132850497477\n",
      "輪次 2 當前輪訓練集損失: 0.642929711577872\n",
      "輪次 3 當前輪訓練集損失: 0.620858833664284\n",
      "輪次 4 當前輪訓練集損失: 0.6015299176167709\n",
      "輪次 5 當前輪訓練集損失: 0.5845422784900919\n",
      "輪次 6 當前輪訓練集損失: 0.5695524409335111\n",
      "輪次 7 當前輪訓練集損失: 0.5562683784138788\n",
      "輪次 8 當前輪訓練集損失: 0.5444432725380884\n",
      "輪次 9 當前輪訓練集損失: 0.5338692023213505\n",
      "輪次 10 當前輪訓練集損失: 0.5243712455591717\n",
      "輪次 11 當前輪訓練集損失: 0.5158022187719777\n",
      "輪次 12 當前輪訓練集損失: 0.5080381239553398\n",
      "輪次 13 當前輪訓練集損失: 0.5009742825267254\n",
      "輪次 14 當前輪訓練集損失: 0.49452209379317347\n",
      "輪次 15 當前輪訓練集損失: 0.4886063387889118\n",
      "輪次 16 當前輪訓練集損失: 0.48316294857712355\n",
      "輪次 17 當前輪訓練集損失: 0.47813716176868465\n",
      "輪次 18 當前輪訓練集損失: 0.4734820048130401\n",
      "輪次 19 當前輪訓練集損失: 0.46915703820427784\n",
      "輪次 20 當前輪訓練集損失: 0.46512732091170617\n",
      "輪次 21 當前輪訓練集損失: 0.46136255354639966\n",
      "輪次 22 當前輪訓練集損失: 0.45783636783749765\n",
      "輪次 23 當前輪訓練集損失: 0.4545257359286322\n",
      "輪次 24 當前輪訓練集損失: 0.45141047791848227\n",
      "輪次 25 當前輪訓練集損失: 0.4484728500955914\n",
      "輪次 26 當前輪訓練集損失: 0.4456971995953261\n",
      "輪次 27 當前輪訓練集損失: 0.44306967386480556\n",
      "輪次 28 當前輪訓練集損失: 0.4405779754723948\n",
      "輪次 29 當前輪訓練集損失: 0.4382111545372311\n",
      "輪次 30 當前輪訓練集損失: 0.4359594324603196\n",
      "輪次 31 當前輪訓練集損失: 0.4338140517766298\n",
      "輪次 32 當前輪訓練集損失: 0.4317671478697758\n",
      "輪次 33 當前輪訓練集損失: 0.42981163903950287\n",
      "輪次 34 當前輪訓練集損失: 0.4279411320212428\n",
      "輪次 35 當前輪訓練集損失: 0.4261498405536124\n",
      "輪次 36 當前輪訓練集損失: 0.42443251499566437\n",
      "輪次 37 當前輪訓練集損失: 0.42278438132836643\n",
      "輪次 38 當前輪訓練集損失: 0.42120108814814033\n",
      "輪次 39 當前輪訓練集損失: 0.41967866048549796\n",
      "輪次 40 當前輪訓練集損失: 0.418213459467879\n",
      "輪次 41 當前輪訓練集損失: 0.41680214699992535\n",
      "輪次 42 當前輪訓練集損失: 0.41544165476246075\n",
      "輪次 43 當前輪訓練集損失: 0.41412915693808655\n",
      "輪次 44 當前輪訓練集損失: 0.41286204616036426\n",
      "輪次 45 當前輪訓練集損失: 0.41163791225813035\n",
      "輪次 46 當前輪訓練集損失: 0.41045452342910055\n",
      "輪次 47 當前輪訓練集損失: 0.40930980952961693\n",
      "輪次 48 當前輪訓練集損失: 0.4082018472118605\n",
      "輪次 49 當前輪訓練集損失: 0.407128846677468\n",
      "輪次 50 當前輪訓練集損失: 0.4060891398483867\n",
      "輪次 51 當前輪訓練集損失: 0.4050811697829158\n",
      "輪次 52 當前輪訓練集損失: 0.404103481187978\n",
      "輪次 53 當前輪訓練集損失: 0.4031547118983903\n",
      "輪次 54 當前輪訓練集損失: 0.4022335852107817\n",
      "輪次 55 當前輪訓練集損失: 0.40133890297428126\n",
      "輪次 56 當前輪訓練集損失: 0.40046953935254576\n",
      "輪次 57 當前輪訓練集損失: 0.3996244351824086\n",
      "輪次 58 當前輪訓練集損失: 0.39880259286368425\n",
      "輪次 59 當前輪訓練集損失: 0.39800307172265975\n",
      "輪次 60 當前輪訓練集損失: 0.39722498379873333\n",
      "輪次 61 當前輪訓練集損失: 0.3964674900096776\n",
      "輪次 62 當前輪訓練集損失: 0.39572979665623614\n",
      "輪次 63 當前輪訓練集損失: 0.39501115223132144\n",
      "輪次 64 當前輪訓練集損失: 0.3943108445030599\n",
      "輪次 65 當前輪訓練集損失: 0.39362819784441033\n",
      "輪次 66 當前輪訓練集損失: 0.3929625707851274\n",
      "輪次 67 當前輪訓練集損失: 0.3923133537645173\n",
      "輪次 68 當前輪訓練集損失: 0.3916799670657792\n",
      "輪次 69 當前輪訓練集損失: 0.3910618589147964\n",
      "輪次 70 當前輪訓練集損失: 0.39045850372806074\n",
      "輪次 71 當前輪訓練集損失: 0.38986940049602703\n",
      "輪次 72 當前輪訓練集損失: 0.38929407128961097\n",
      "輪次 73 當前輪訓練集損失: 0.38873205987881077\n",
      "輪次 74 當前輪訓練集損失: 0.388182930453546\n",
      "輪次 75 當前輪訓練集損失: 0.3876462664377981\n",
      "輪次 76 當前輪訓練集損失: 0.3871216693890235\n",
      "輪次 77 當前輪訓練集損失: 0.3866087579755928\n",
      "輪次 78 當前輪訓練集損失: 0.38610716702571085\n",
      "輪次 79 當前輪訓練集損失: 0.38561654664189743\n",
      "輪次 80 當前輪訓練集損失: 0.38513656137567015\n",
      "輪次 81 當前輪訓練集損失: 0.3846668894575669\n",
      "輪次 82 當前輪訓練集損失: 0.38420722207809865\n",
      "輪次 83 當前輪訓練集損失: 0.38375726271562294\n",
      "輪次 84 當前輪訓練集損失: 0.3833167265074909\n",
      "輪次 85 當前輪訓練集損失: 0.382885339661146\n",
      "輪次 86 當前輪訓練集損失: 0.3824628389021462\n",
      "輪次 87 當前輪訓練集損失: 0.38204897095634366\n",
      "輪次 88 當前輪訓練集損失: 0.3816434920636964\n",
      "輪次 89 當前輪訓練集損失: 0.3812461675214007\n",
      "輪次 90 當前輪訓練集損失: 0.3808567712542277\n",
      "輪次 91 當前輪訓練集損失: 0.3804750854101245\n",
      "輪次 92 當前輪訓練集損失: 0.3801008999793006\n",
      "輪次 93 當前輪訓練集損失: 0.37973401243516336\n",
      "輪次 94 當前輪訓練集損失: 0.37937422739560206\n",
      "輪次 95 當前輪訓練集損失: 0.37902135630323347\n",
      "輪次 96 當前輪訓練集損失: 0.3786752171233402\n",
      "輪次 97 當前輪訓練集損失: 0.3783356340583223\n",
      "輪次 98 當前輪訓練集損失: 0.37800243727758204\n",
      "輪次 99 當前輪訓練集損失: 0.377675462661838\n",
      "輪次 100 當前輪訓練集損失: 0.3773545515609444\n",
      "輪次 101 當前輪訓練集損失: 0.3770395505643593\n",
      "輪次 102 當前輪訓練集損失: 0.3767303112834674\n",
      "輪次 103 當前輪訓練集損失: 0.3764266901450243\n",
      "輪次 104 當前輪訓練集損失: 0.3761285481950381\n",
      "輪次 105 當前輪訓練集損失: 0.37583575091245675\n",
      "輪次 106 當前輪訓練集損失: 0.3755481680320737\n",
      "輪次 107 當前輪訓練集損失: 0.37526567337610184\n",
      "輪次 108 當前輪訓練集損失: 0.37498814469391006\n",
      "輪次 109 當前輪訓練集損失: 0.3747154635094467\n",
      "輪次 110 當前輪訓練集損失: 0.3744475149759079\n",
      "輪次 111 當前輪訓練集損失: 0.3741841877372396\n",
      "輪次 112 當前輪訓練集損失: 0.37392537379608787\n",
      "輪次 113 當前輪訓練集損失: 0.373670968387838\n",
      "輪次 114 當前輪訓練集損失: 0.37342086986040746\n",
      "輪次 115 當前輪訓練集損失: 0.37317497955947765\n",
      "輪次 116 當前輪訓練集損失: 0.37293320171887107\n",
      "輪次 117 當前輪訓練集損失: 0.3726954433557965\n",
      "輪次 118 當前輪訓練集損失: 0.37246161417070783\n",
      "輪次 119 當前輪訓練集損失: 0.37223162645153013\n",
      "輪次 120 當前輪訓練集損失: 0.3720053949820283\n",
      "輪次 121 當前輪訓練集損失: 0.3717828369541044\n",
      "輪次 122 當前輪訓練集損失: 0.3715638718838221\n",
      "輪次 123 當前輪訓練集損失: 0.3713484215309716\n",
      "輪次 124 當前輪訓練集損失: 0.37113640982199503\n",
      "輪次 125 當前輪訓練集損失: 0.37092776277610817\n",
      "輪次 126 當前輪訓練集損失: 0.3707224084344585\n",
      "輪次 127 當前輪訓練集損失: 0.37052027679217375\n",
      "輪次 128 當前輪訓練集損失: 0.3703212997331591\n",
      "輪次 129 當前輪訓練集損失: 0.3701254109675123\n",
      "輪次 130 當前輪訓練集損失: 0.3699325459714327\n",
      "輪次 131 當前輪訓練集損失: 0.36974264192950473\n",
      "輪次 132 當前輪訓練集損失: 0.3695556376792468\n",
      "輪次 133 當前輪訓練集損失: 0.3693714736578188\n",
      "輪次 134 當前輪訓練集損失: 0.3691900918507912\n",
      "輪次 135 當前輪訓練集損失: 0.3690114357428781\n",
      "輪次 136 當前輪訓練集損失: 0.3688354502705493\n",
      "輪次 137 當前輪訓練集損失: 0.36866208177643406\n",
      "輪次 138 當前輪訓練集損失: 0.36849127796543757\n",
      "輪次 139 當前輪訓練集損失: 0.36832298786249507\n",
      "輪次 140 當前輪訓練集損失: 0.3681571617718906\n",
      "輪次 141 當前輪訓練集損失: 0.3679937512380732\n",
      "輪次 142 當前輪訓練集損失: 0.36783270900790416\n",
      "輪次 143 當前輪訓練集損失: 0.36767398899427667\n",
      "輪次 144 當前輪訓練集損失: 0.3675175462410465\n",
      "輪次 145 當前輪訓練集損失: 0.36736333688921946\n",
      "輪次 146 當前輪訓練集損失: 0.3672113181443432\n",
      "輪次 147 當前輪訓練集損失: 0.36706144824505293\n",
      "輪次 148 當前輪訓練集損失: 0.36691368643272154\n",
      "輪次 149 當前輪訓練集損失: 0.3667679929221722\n",
      "輪次 150 當前輪訓練集損失: 0.3666243288734055\n",
      "輪次 151 當前輪訓練集損失: 0.3664826563643046\n",
      "輪次 152 當前輪訓練集損失: 0.36634293836427534\n",
      "輪次 153 當前輪訓練集損失: 0.36620513870878457\n",
      "輪次 154 當前輪訓練集損失: 0.3660692220747635\n",
      "輪次 155 當前輪訓練集損失: 0.3659351539568376\n",
      "輪次 156 當前輪訓練集損失: 0.36580290064435494\n",
      "輪次 157 當前輪訓練集損失: 0.36567242919917725\n",
      "輪次 158 當前輪訓練集損失: 0.3655437074342088\n",
      "輪次 159 當前輪訓練集損失: 0.3654167038926306\n",
      "輪次 160 當前輪訓練集損失: 0.36529138782781556\n",
      "輪次 161 當前輪訓練集損失: 0.3651677291838973\n",
      "輪次 162 當前輪訓練集損失: 0.36504569857696784\n",
      "輪次 163 當前輪訓練集損失: 0.3649252672768816\n",
      "輪次 164 當前輪訓練集損失: 0.36480640718964163\n",
      "輪次 165 當前輪訓練集損失: 0.364689090840347\n",
      "輪次 166 當前輪訓練集損失: 0.36457329135668143\n",
      "輪次 167 當前輪訓練集損失: 0.36445898245292063\n",
      "輪次 168 當前輪訓練集損失: 0.36434613841444324\n",
      "輪次 169 當前輪訓練集損失: 0.36423473408272317\n",
      "輪次 170 當前輪訓練集損失: 0.36412474484078855\n",
      "輪次 171 當前輪訓練集損失: 0.3640161465991297\n",
      "輪次 172 當前輪訓練集損失: 0.3639089157820387\n",
      "輪次 173 當前輪訓練集損失: 0.3638030293143685\n",
      "輪次 174 當前輪訓練集損失: 0.3636984646086927\n",
      "輪次 175 當前輪訓練集損失: 0.3635951995528551\n",
      "輪次 176 當前輪訓練集損失: 0.36349321249789285\n",
      "輪次 177 當前輪訓練集損失: 0.363392482246323\n",
      "輪次 178 當前輪訓練集損失: 0.3632929880407769\n",
      "輪次 179 當前輪訓練集損失: 0.36319470955297245\n",
      "輪次 180 當前輪訓練集損失: 0.3630976268730117\n",
      "輪次 181 當前輪訓練集損失: 0.36300172049899315\n",
      "輪次 182 當前輪訓練集損失: 0.36290697132692745\n",
      "輪次 183 當前輪訓練集損失: 0.362813360640947\n",
      "輪次 184 當前輪訓練集損失: 0.36272087010379916\n",
      "輪次 185 當前輪訓練集損失: 0.36262948174761356\n",
      "輪次 186 當前輪訓練集損失: 0.362539177964934\n",
      "輪次 187 當前輪訓練集損失: 0.3624499415000072\n",
      "輪次 188 當前輪訓練集損失: 0.36236175544031896\n",
      "輪次 189 當前輪訓練集損失: 0.36227460320836996\n",
      "輪次 190 當前輪訓練集損失: 0.36218846855368353\n",
      "輪次 191 當前輪訓練集損失: 0.36210333554503726\n",
      "輪次 192 當前輪訓練集損失: 0.36201918856291215\n",
      "輪次 193 當前輪訓練集損失: 0.3619360122921511\n",
      "輪次 194 當前輪訓練集損失: 0.36185379171482146\n",
      "輪次 195 當前輪訓練集損失: 0.3617725121032734\n",
      "輪次 196 當前輪訓練集損失: 0.36169215901338925\n",
      "輪次 197 當前輪訓練集損失: 0.36161271827801794\n",
      "輪次 198 當前輪訓練集損失: 0.3615341760005863\n",
      "輪次 199 當前輪訓練集損失: 0.3614565185488857\n",
      "輪次 200 當前輪訓練集損失: 0.36137973254902445\n",
      "輪次 201 當前輪訓練集損失: 0.36130380487954344\n",
      "輪次 202 當前輪訓練集損失: 0.36122872266568934\n",
      "輪次 203 當前輪訓練集損失: 0.36115447327384004\n",
      "輪次 204 當前輪訓練集損失: 0.36108104430607746\n",
      "輪次 205 當前輪訓練集損失: 0.3610084235949051\n",
      "輪次 206 當前輪訓練集損失: 0.3609365991981032\n",
      "輪次 207 當前輪訓練集損失: 0.36086555939371906\n",
      "輪次 208 當前輪訓練集損失: 0.3607952926751886\n",
      "輪次 209 當前輪訓練集損失: 0.3607257877465837\n",
      "輪次 210 當前輪訓練集損失: 0.360657033517984\n",
      "輪次 211 當前輪訓練集損失: 0.36058901910096586\n",
      "輪次 212 當前輪訓練集損失: 0.3605217338042094\n",
      "輪次 213 當前輪訓練集損失: 0.3604551671292164\n",
      "輪次 214 當前輪訓練集損失: 0.36038930876613745\n",
      "輪次 215 當前輪訓練集損失: 0.36032414858970585\n",
      "輪次 216 當前輪訓練集損失: 0.3602596766552726\n",
      "輪次 217 當前輪訓練集損失: 0.3601958831949431\n",
      "輪次 218 當前輪訓練集損失: 0.3601327586138091\n",
      "輪次 219 當前輪訓練集損失: 0.3600702934862758\n",
      "輪次 220 當前輪訓練集損失: 0.3600084785524796\n",
      "輪次 221 當前輪訓練集損失: 0.3599473047147953\n",
      "輪次 222 當前輪訓練集損失: 0.35988676303442907\n",
      "輪次 223 當前輪訓練集損失: 0.35982684472809495\n",
      "輪次 224 當前輪訓練集損失: 0.3597675411647737\n",
      "輪次 225 當前輪訓練集損失: 0.3597088438625498\n",
      "輪次 226 當前輪訓練集損失: 0.359650744485526\n",
      "輪次 227 當前輪訓練集損失: 0.35959323484081224\n",
      "輪次 228 當前輪訓練集損失: 0.35953630687558713\n",
      "輪次 229 當前輪訓練集損失: 0.35947995267423105\n",
      "輪次 230 當前輪訓練集損失: 0.35942416445552633\n",
      "輪次 231 當前輪訓練集損失: 0.3593689345699258\n",
      "輪次 232 當前輪訓練集損失: 0.3593142554968852\n",
      "輪次 233 當前輪訓練集損失: 0.3592601198422595\n",
      "輪次 234 當前輪訓練集損失: 0.3592065203357603\n",
      "輪次 235 當前輪訓練集損失: 0.35915344982847325\n",
      "輪次 236 當前輪訓練集損失: 0.3591009012904333\n",
      "輪次 237 當前輪訓練集損失: 0.3590488678082573\n",
      "輪次 238 當前輪訓練集損失: 0.3589973425828309\n",
      "輪次 239 當前輪訓練集損失: 0.3589463189270493\n",
      "輪次 240 當前輪訓練集損失: 0.35889579026361074\n",
      "輪次 241 當前輪訓練集損失: 0.3588457501228602\n",
      "輪次 242 當前輪訓練集損失: 0.35879619214068265\n",
      "輪次 243 當前輪訓練集損失: 0.35874711005644483\n",
      "輪次 244 當前輪訓練集損失: 0.3586984977109834\n",
      "輪次 245 當前輪訓練集損失: 0.35865034904463927\n",
      "輪次 246 當前輪訓練集損失: 0.3586026580953361\n",
      "輪次 247 當前輪訓練集損失: 0.3585554189967023\n",
      "輪次 248 當前輪訓練集損失: 0.35850862597623506\n",
      "輪次 249 當前輪訓練集損失: 0.3584622733535058\n",
      "輪次 250 當前輪訓練集損失: 0.358416355538405\n",
      "輪次 251 當前輪訓練集損失: 0.3583708670294271\n",
      "輪次 252 當前輪訓練集損失: 0.35832580241199274\n",
      "輪次 253 當前輪訓練集損失: 0.3582811563568081\n",
      "輪次 254 當前輪訓練集損失: 0.3582369236182602\n",
      "輪次 255 當前輪訓練集損失: 0.35819309903284835\n",
      "輪次 256 當前輪訓練集損失: 0.3581496775176489\n",
      "輪次 257 當前輪訓練集損失: 0.3581066540688136\n",
      "輪次 258 當前輪訓練集損失: 0.35806402376010127\n",
      "輪次 259 當前輪訓練集損失: 0.3580217817414405\n",
      "輪次 260 當前輪訓練集損失: 0.35797992323752403\n",
      "輪次 261 當前輪訓練集損失: 0.3579384435464328\n",
      "輪次 262 當前輪訓練集損失: 0.35789733803828966\n",
      "輪次 263 當前輪訓練集損失: 0.35785660215394255\n",
      "輪次 264 當前輪訓練集損失: 0.35781623140367447\n",
      "輪次 265 當前輪訓練集損失: 0.3577762213659421\n",
      "輪次 266 當前輪訓練集損失: 0.3577365676861403\n",
      "輪次 267 當前輪訓練集損失: 0.35769726607539337\n",
      "輪次 268 當前輪訓練集損失: 0.3576583123093706\n",
      "輪次 269 當前輪訓練集損失: 0.35761970222712836\n",
      "輪次 270 當前輪訓練集損失: 0.3575814317299748\n",
      "輪次 271 當前輪訓練集損失: 0.35754349678035935\n",
      "輪次 272 當前輪訓練集損失: 0.3575058934007843\n",
      "輪次 273 當前輪訓練集損失: 0.3574686176727401\n",
      "輪次 274 當前輪訓練集損失: 0.35743166573566165\n",
      "輪次 275 當前輪訓練集損失: 0.3573950337859063\n",
      "輪次 276 當前輪訓練集損失: 0.3573587180757535\n",
      "輪次 277 當前輪訓練集損失: 0.35732271491242373\n",
      "輪次 278 當前輪訓練集損失: 0.35728702065711854\n",
      "輪次 279 當前輪訓練集損失: 0.35725163172408\n",
      "輪次 280 當前輪訓練集損失: 0.35721654457966784\n",
      "輪次 281 當前輪訓練集損失: 0.35718175574145733\n",
      "輪次 282 當前輪訓練集損失: 0.35714726177735384\n",
      "輪次 283 當前輪訓練集損失: 0.35711305930472587\n",
      "輪次 284 當前輪訓練集損失: 0.3570791449895552\n",
      "輪次 285 當前輪訓練集損失: 0.35704551554560376\n",
      "輪次 286 當前輪訓練集損失: 0.35701216773359823\n",
      "輪次 287 當前輪訓練集損失: 0.35697909836042874\n",
      "輪次 288 當前輪訓練集損失: 0.3569463042783661\n",
      "輪次 289 當前輪訓練集損失: 0.35691378238429217\n",
      "輪次 290 當前輪訓練集損失: 0.3568815296189464\n",
      "輪次 291 當前輪訓練集損失: 0.35684954296618737\n",
      "輪次 292 當前輪訓練集損失: 0.3568178194522683\n",
      "輪次 293 當前輪訓練集損失: 0.35678635614512694\n",
      "輪次 294 當前輪訓練集損失: 0.35675515015368864\n",
      "輪次 295 當前輪訓練集損失: 0.3567241986271849\n",
      "輪次 296 當前輪訓練集損失: 0.356693498754482\n",
      "輪次 297 當前輪訓練集損失: 0.3566630477634254\n",
      "輪次 298 當前輪訓練集損失: 0.35663284292019554\n",
      "輪次 299 當前輪訓練集損失: 0.35660288152867564\n",
      "輪次 300 當前輪訓練集損失: 0.3565731609298324\n",
      "輪次 301 當前輪訓練集損失: 0.3565436785011082\n",
      "輪次 302 當前輪訓練集損失: 0.3565144316558246\n",
      "輪次 303 當前輪訓練集損失: 0.35648541784259763\n",
      "輪次 304 當前輪訓練集損失: 0.35645663454476384\n",
      "輪次 305 當前輪訓練集損失: 0.356428079279817\n",
      "輪次 306 當前輪訓練集損失: 0.35639974959885623\n",
      "輪次 307 當前輪訓練集損失: 0.3563716430860428\n",
      "輪次 308 當前輪訓練集損失: 0.3563437573580698\n",
      "輪次 309 當前輪訓練集損失: 0.35631609006363835\n",
      "輪次 310 當前輪訓練集損失: 0.35628863888294665\n",
      "輪次 311 當前輪訓練集損失: 0.3562614015271864\n",
      "輪次 312 當前輪訓練集損失: 0.3562343757380494\n",
      "輪次 313 當前輪訓練集損失: 0.3562075592872437\n",
      "輪次 314 當前輪訓練集損失: 0.3561809499760174\n",
      "輪次 315 當前輪訓練集損失: 0.3561545456346924\n",
      "輪次 316 當前輪訓練集損失: 0.35612834412220584\n",
      "輪次 317 當前輪訓練集損失: 0.35610234332566054\n",
      "輪次 318 當前輪訓練集損失: 0.35607654115988335\n",
      "輪次 319 當前輪訓練集損失: 0.35605093556699136\n",
      "輪次 320 當前輪訓練集損失: 0.3560255245159662\n",
      "輪次 321 當前輪訓練集損失: 0.3560003060022365\n",
      "輪次 322 當前輪訓練集損失: 0.35597527804726614\n",
      "輪次 323 當前輪訓練集損失: 0.3559504386981524\n",
      "輪次 324 當前輪訓練集損失: 0.3559257860272295\n",
      "輪次 325 當前輪訓練集損失: 0.3559013181316796\n",
      "輪次 326 當前輪訓練集損失: 0.3558770331331511\n",
      "輪次 327 當前輪訓練集損失: 0.3558529291773837\n",
      "輪次 328 當前輪訓練集損失: 0.3558290044338396\n",
      "輪次 329 當前輪訓練集損失: 0.35580525709534205\n",
      "輪次 330 當前輪訓練集損失: 0.3557816853777192\n",
      "輪次 331 當前輪訓練集損失: 0.3557582875194555\n",
      "輪次 332 當前輪訓練集損失: 0.35573506178134795\n",
      "輪次 333 當前輪訓練集損失: 0.3557120064461698\n",
      "輪次 334 當前輪訓練集損失: 0.35568911981833834\n",
      "輪次 335 當前輪訓練集損失: 0.3556664002235901\n",
      "輪次 336 當前輪訓練集損失: 0.35564384600866106\n",
      "輪次 337 當前輪訓練集損失: 0.3556214555409723\n",
      "輪次 338 當前輪訓練集損失: 0.3555992272083209\n",
      "輪次 339 當前輪訓練集損失: 0.35557715941857715\n",
      "輪次 340 當前輪訓練集損失: 0.3555552505993857\n",
      "輪次 341 當前輪訓練集損失: 0.35553349919787314\n",
      "輪次 342 當前輪訓練集損失: 0.35551190368035873\n",
      "輪次 343 當前輪訓練集損失: 0.3554904625320725\n",
      "輪次 344 當前輪訓練集損失: 0.3554691742568766\n",
      "輪次 345 當前輪訓練集損失: 0.3554480373769911\n",
      "輪次 346 當前輪訓練集損失: 0.35542705043272593\n",
      "輪次 347 當前輪訓練集損失: 0.35540621198221567\n",
      "輪次 348 當前輪訓練集損失: 0.35538552060116035\n",
      "輪次 349 當前輪訓練集損失: 0.3553649748825693\n",
      "輪次 350 當前輪訓練集損失: 0.35534457343651044\n",
      "輪次 351 當前輪訓練集損失: 0.35532431488986294\n",
      "輪次 352 當前輪訓練集損失: 0.3553041978860743\n",
      "輪次 353 當前輪訓練集損失: 0.3552842210849217\n",
      "輪次 354 當前輪訓練集損失: 0.35526438316227704\n",
      "輪次 355 當前輪訓練集損失: 0.3552446828098763\n",
      "輪次 356 當前輪訓練集損失: 0.35522511873509166\n",
      "輪次 357 當前輪訓練集損失: 0.35520568966070887\n",
      "輪次 358 當前輪訓練集損失: 0.35518639432470733\n",
      "輪次 359 當前輪訓練集損失: 0.355167231480044\n",
      "輪次 360 當前輪訓練集損失: 0.35514819989444074\n",
      "輪次 361 當前輪訓練集損失: 0.3551292983501758\n",
      "輪次 362 當前輪訓練集損失: 0.3551105256438775\n",
      "輪次 363 當前輪訓練集損失: 0.3550918805863227\n",
      "輪次 364 當前輪訓練集損失: 0.355073362002237\n",
      "輪次 365 當前輪訓練集損失: 0.35505496873010006\n",
      "輪次 366 當前輪訓練集損失: 0.35503669962195217\n",
      "輪次 367 當前輪訓練集損失: 0.35501855354320516\n",
      "輪次 368 當前輪訓練集損失: 0.35500052937245596\n",
      "輪次 369 當前輪訓練集損失: 0.3549826260013032\n",
      "輪次 370 當前輪訓練集損失: 0.35496484233416714\n",
      "輪次 371 當前輪訓練集損失: 0.35494717728811137\n",
      "輪次 372 當前輪訓練集損失: 0.35492962979266884\n",
      "輪次 373 當前輪訓練集損失: 0.35491219878966934\n",
      "輪次 374 當前輪訓練集損失: 0.354894883233071\n",
      "輪次 375 當前輪訓練集損失: 0.35487768208879306\n",
      "輪次 376 當前輪訓練集損失: 0.35486059433455247\n",
      "輪次 377 當前輪訓練集損失: 0.3548436189597027\n",
      "輪次 378 當前輪訓練集損失: 0.35482675496507465\n",
      "輪次 379 當前輪訓練集損失: 0.35481000136282076\n",
      "輪次 380 當前輪訓練集損失: 0.35479335717626104\n",
      "輪次 381 當前輪訓練集損失: 0.354776821439732\n",
      "輪次 382 當前輪訓練集損失: 0.354760393198437\n",
      "輪次 383 當前輪訓練集損失: 0.3547440715083008\n",
      "輪次 384 當前輪訓練集損失: 0.35472785543582386\n",
      "輪次 385 當前輪訓練集損失: 0.3547117440579409\n",
      "輪次 386 當前輪訓練集損失: 0.35469573646188135\n",
      "輪次 387 當前輪訓練集損失: 0.3546798317450307\n",
      "輪次 388 當前輪訓練集損失: 0.35466402901479543\n",
      "輪次 389 當前輪訓練集損失: 0.3546483273884694\n",
      "輪次 390 當前輪訓練集損失: 0.3546327259931024\n",
      "輪次 391 當前輪訓練集損失: 0.35461722396537076\n",
      "輪次 392 當前輪訓練集損失: 0.35460182045144933\n",
      "輪次 393 當前輪訓練集損失: 0.35458651460688667\n",
      "輪次 394 當前輪訓練集損失: 0.3545713055964812\n",
      "輪次 395 當前輪訓練集損失: 0.3545561925941592\n",
      "輪次 396 當前輪訓練集損失: 0.35454117478285535\n",
      "輪次 397 當前輪訓練集損失: 0.3545262513543944\n",
      "輪次 398 當前輪訓練集損失: 0.3545114215093748\n",
      "輪次 399 當前輪訓練集損失: 0.3544966844570545\n",
      "輪次 400 當前輪訓練集損失: 0.3544820394152381\n",
      "輪次 401 當前輪訓練集損失: 0.3544674856101652\n",
      "輪次 402 當前輪訓練集損失: 0.3544530222764022\n",
      "輪次 403 當前輪訓練集損失: 0.35443864865673275\n",
      "輪次 404 當前輪訓練集損失: 0.35442436400205335\n",
      "輪次 405 當前輪訓練集損失: 0.35441016757126764\n",
      "輪次 406 當前輪訓練集損失: 0.3543960586311838\n",
      "輪次 407 當前輪訓練集損失: 0.3543820364564127\n",
      "輪次 408 當前輪訓練集損失: 0.3543681003292684\n",
      "輪次 409 當前輪訓練集損失: 0.35435424953966926\n",
      "輪次 410 當前輪訓練集損失: 0.3543404833850409\n",
      "輪次 411 當前輪訓練集損失: 0.35432680117022086\n",
      "輪次 412 當前輪訓練集損失: 0.35431320220736384\n",
      "輪次 413 當前輪訓練集損失: 0.35429968581584953\n",
      "輪次 414 當前輪訓練集損失: 0.3542862513221905\n",
      "輪次 415 當前輪訓練集損失: 0.3542728980599425\n",
      "輪次 416 當前輪訓練集損失: 0.35425962536961547\n",
      "輪次 417 當前輪訓練集損失: 0.3542464325985859\n",
      "輪次 418 當前輪訓練集損失: 0.35423331910101075\n",
      "輪次 419 當前輪訓練集損失: 0.3542202842377423\n",
      "輪次 420 當前輪訓練集損失: 0.3542073273762448\n",
      "輪次 421 當前輪訓練集損失: 0.3541944478905108\n",
      "輪次 422 當前輪訓練集損失: 0.3541816451609814\n",
      "輪次 423 當前輪訓練集損失: 0.35416891857446453\n",
      "輪次 424 當前輪訓練集損失: 0.35415626752405693\n",
      "輪次 425 當前輪訓練集損失: 0.3541436914090657\n",
      "輪次 426 當前輪訓練集損失: 0.35413118963493156\n",
      "輪次 427 當前輪訓練集損失: 0.35411876161315353\n",
      "輪次 428 當前輪訓練集損失: 0.3541064067612138\n",
      "輪次 429 當前輪訓練集損失: 0.35409412450250444\n",
      "輪次 430 當前輪訓練集損失: 0.35408191426625496\n",
      "輪次 431 當前輪訓練集損失: 0.3540697754874606\n",
      "輪次 432 當前輪訓練集損失: 0.35405770760681193\n",
      "輪次 433 當前輪訓練集損失: 0.3540457100706255\n",
      "輪次 434 當前輪訓練集損失: 0.35403378233077554\n",
      "輪次 435 當前輪訓練集損失: 0.35402192384462566\n",
      "輪次 436 當前輪訓練集損失: 0.35401013407496296\n",
      "輪次 437 當前輪訓練集損失: 0.3539984124899324\n",
      "輪次 438 當前輪訓練集損失: 0.3539867585629717\n",
      "輪次 439 當前輪訓練集損失: 0.3539751717727474\n",
      "輪次 440 當前輪訓練集損失: 0.3539636516030927\n",
      "輪次 441 當前輪訓練集損失: 0.35395219754294455\n",
      "輪次 442 當前輪訓練集損失: 0.35394080908628306\n",
      "輪次 443 當前輪訓練集損失: 0.35392948573207084\n",
      "輪次 444 當前輪訓練集損失: 0.3539182269841933\n",
      "輪次 445 當前輪訓練集損失: 0.35390703235140064\n",
      "輪次 446 當前輪訓練集損失: 0.35389590134724924\n",
      "輪次 447 當前輪訓練集損失: 0.353884833490045\n",
      "輪次 448 當前輪訓練集損失: 0.35387382830278713\n",
      "輪次 449 當前輪訓練集損失: 0.35386288531311216\n",
      "輪次 450 當前輪訓練集損失: 0.3538520040532397\n",
      "輪次 451 當前輪訓練集損失: 0.3538411840599179\n",
      "輪次 452 當前輪訓練集損失: 0.35383042487437083\n",
      "輪次 453 當前輪訓練集損失: 0.3538197260422454\n",
      "輪次 454 當前輪訓練集損失: 0.3538090871135596\n",
      "輪次 455 當前輪訓練集損失: 0.3537985076426513\n",
      "輪次 456 當前輪訓練集損失: 0.35378798718812887\n",
      "輪次 457 當前輪訓練集損失: 0.35377752531281925\n",
      "輪次 458 當前輪訓練集損失: 0.35376712158372114\n",
      "輪次 459 當前輪訓練集損失: 0.35375677557195523\n",
      "輪次 460 當前輪訓練集損失: 0.35374648685271676\n",
      "輪次 461 當前輪訓練集損失: 0.35373625500522843\n",
      "輪次 462 當前輪訓練集損失: 0.353726079612694\n",
      "輪次 463 當前輪訓練集損失: 0.3537159602622522\n",
      "輪次 464 當前輪訓練集損失: 0.3537058965449317\n",
      "輪次 465 當前輪訓練集損失: 0.35369588805560626\n",
      "輪次 466 當前輪訓練集損失: 0.3536859343929508\n",
      "輪次 467 當前輪訓練集損失: 0.3536760351593977\n",
      "輪次 468 當前輪訓練集損失: 0.3536661899610945\n",
      "輪次 469 當前輪訓練集損失: 0.35365639840786073\n",
      "輪次 470 當前輪訓練集損失: 0.3536466601131466\n",
      "輪次 471 當前輪訓練集損失: 0.35363697469399213\n",
      "輪次 472 當前輪訓練集損失: 0.35362734177098537\n",
      "輪次 473 當前輪訓練集損失: 0.35361776096822367\n",
      "輪次 474 當前輪訓練集損失: 0.353608231913273\n",
      "輪次 475 當前輪訓練集損失: 0.35359875423712933\n",
      "輪次 476 當前輪訓練集損失: 0.35358932757418005\n",
      "輪次 477 當前輪訓練集損失: 0.3535799515621653\n",
      "輪次 478 當前輪訓練集損失: 0.35357062584214166\n",
      "輪次 479 當前輪訓練集損失: 0.3535613500584436\n",
      "輪次 480 當前輪訓練集損失: 0.3535521238586479\n",
      "輪次 481 當前輪訓練集損失: 0.353542946893537\n",
      "輪次 482 當前輪訓練集損失: 0.3535338188170636\n",
      "輪次 483 當前輪訓練集損失: 0.35352473928631517\n",
      "輪次 484 當前輪訓練集損失: 0.3535157079614798\n",
      "輪次 485 當前輪訓練集損失: 0.35350672450581094\n",
      "輪次 486 當前輪訓練集損失: 0.3534977885855944\n",
      "輪次 487 當前輪訓練集損失: 0.35348889987011467\n",
      "輪次 488 當前輪訓練集損失: 0.3534800580316215\n",
      "輪次 489 當前輪訓練集損失: 0.3534712627452982\n",
      "輪次 490 當前輪訓練集損失: 0.3534625136892286\n",
      "輪次 491 當前輪訓練集損失: 0.35345381054436564\n",
      "輪次 492 當前輪訓練集損失: 0.3534451529945002\n",
      "輪次 493 當前輪訓練集損失: 0.3534365407262301\n",
      "輪次 494 當前輪訓練集損失: 0.3534279734289292\n",
      "輪次 495 當前輪訓練集損失: 0.3534194507947177\n",
      "輪次 496 當前輪訓練集損失: 0.35341097251843234\n",
      "輪次 497 當前輪訓練集損失: 0.3534025382975963\n",
      "輪次 498 當前輪訓練集損失: 0.3533941478323912\n",
      "輪次 499 當前輪訓練集損失: 0.3533858008256276\n",
      "輪次 500 當前輪訓練集損失: 0.35337749698271703\n",
      "訓練最終損失: 0.35337749698271703\n",
      "Logistic regression training accuracy: 84.71%\n"
     ]
    }
   ],
   "source": [
    "loss_history,weight_history,bias_history = logistic_regression(X_train,y_train,weight,bias,alpha,iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f76b467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression testing accuracy: 85.25% \n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test,weight_history[-1],bias_history[-1])\n",
    "testing_acc = 100 - np.mean(np.abs(y_pred - y_test)) * 100\n",
    "print('Logistic regression testing accuracy: {:.2f}% '.format(testing_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ea81057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_regression_predict_value: [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Logistic_regression_predict_value:',predict(X_test,weight_history[-1],bias_history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "10160c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwbElEQVR4nO3deXxV1bn/8c+TBBLmMagQNICgDNqgEadrAb1aHCqtYqtVK9VWbVUcWhU7Ofaq7f3h0DrUttZrW6c64lApoigOCAFBGRUi1SAiBAmTDEme3x9rh5yEAyThHDZJvu/Xa7/O2Xvt4dnhcJ6z9tp7LXN3REREasuIOwAREdkzKUGIiEhSShAiIpKUEoSIiCSlBCEiIkllxR1AqnTt2tXz8/PjDkNEpFGZMWPGSnfPTVbWZBJEfn4+RUVFcYchItKomNl/tlemS0wiIpKUEoSIiCSlBCEiIkk1mTYIEdnzbNmyhZKSEjZu3Bh3KM1eTk4OeXl5tGjRos7bKEGISNqUlJTQrl078vPzMbO4w2m23J3S0lJKSkro1atXnbfTJSYRSZuNGzfSpUsXJYeYmRldunSpd01OCUJE0krJYc/QkH8HJQgREUlKCWLNGhg6FJ54Iu5IRCTFSktLKSgooKCggL333psePXpsnd+8efMOty0qKmLMmDE7PcZRRx2VklgnT57MKaeckpJ9pYoaqTMz4Y034OST445ERFKsS5cuzJo1C4AbbriBtm3b8rOf/WxreXl5OVlZyb8GCwsLKSws3Okx3n777ZTEuidSDSInJ7zqNjyRZmH06NFcfPHFHH744VxzzTVMmzaNI488ksGDB3PUUUexcOFCoOYv+htuuIHzzz+fYcOG0bt3b+6+++6t+2vbtu3W9YcNG8aoUaM48MADOfvss6kasfOll17iwAMP5NBDD2XMmDH1qik8+uijHHTQQQwaNIhrr70WgIqKCkaPHs2gQYM46KCDuOOOOwC4++67GTBgAAcffDBnnnnmLv+tVIPIzIQWLeCrr+KORKRJu+IKiH7Mp0xBAdx5Z/23Kykp4e233yYzM5M1a9YwZcoUsrKyeOWVV/j5z3/OU089tc02CxYs4LXXXmPt2rUccMAB/PjHP97mmYL33nuPuXPn0r17d44++mjeeustCgsLueiii3jjjTfo1asXZ511Vp3j/Oyzz7j22muZMWMGnTp14oQTTuDZZ5+lZ8+eLF26lDlz5gCwevVqAG677TY+/vhjsrOzty7bFapBQKhFqAYh0mycccYZZGZmAlBWVsYZZ5zBoEGDuPLKK5k7d27SbU4++WSys7Pp2rUr3bp1Y/ny5dusM2TIEPLy8sjIyKCgoIAlS5awYMECevfuvfX5g/okiOnTpzNs2DByc3PJysri7LPP5o033qB3794UFxdz2WWX8fLLL9O+fXsADj74YM4++2z+/ve/b/fSWX2oBgEwZAh07x53FCJNWkN+6adLmzZttr7/1a9+xfDhw3nmmWdYsmQJw4YNS7pNdnb21veZmZmUl5c3aJ1U6NSpE7Nnz2bChAncf//9PPHEEzz44IO8+OKLvPHGGzz//PP85je/4YMPPtilRKEaBMArr8DVV8cdhYjEoKysjB49egDw0EMPpXz/BxxwAMXFxSxZsgSAxx9/vM7bDhkyhNdff52VK1dSUVHBo48+ytChQ1m5ciWVlZWcfvrp3HLLLcycOZPKyko+/fRThg8fzu23305ZWRnr1q3bpdhVgxCRZu2aa67hvPPO45ZbbuHkNNzN2KpVK+69915GjBhBmzZtOOyww7a77qRJk8jLy9s6/89//pPbbruN4cOH4+6cfPLJjBw5ktmzZ/ODH/yAyspKAG699VYqKio455xzKCsrw90ZM2YMHTt23KXYraqVvbErLCz0hgwYtGYNLBryPfYe2JnuT/0hDZGJNF/z58+nf//+cYcRu3Xr1tG2bVvcnUsuuYS+ffty5ZVX7vY4kv17mNkMd096P2+zv8S0ZQtsWvgxW+Z+GHcoItJE/elPf6KgoICBAwdSVlbGRRddFHdIddLsLzG1aQNf0YqMjbrNVUTS48orr4ylxrCrmn0NIjsbNpGDbdZtriIiiZp9gjCDzVmtyFCCEBGpodlfYgJYmFNA187t0ZMQIiLVlCCAB/b6FbMK4ei4AxER2YMoQRAaqtevjzsKEUm10tJSjjvuOAA+//xzMjMzyc3NBWDatGm0bNlyh9tPnjyZli1bJu3S+6GHHqKoqIg//KHp3h6vBAFcuPq3nPLKX4H5cYciIim0s+6+d2by5Mm0bds2ZWM+NDZpbaQ2sxFmttDMFpnZ2O2s8x0zm2dmc83skYTlFWY2K5rGpzPODplr6blhITSRhwZFZPtmzJjB0KFDOfTQQ/nGN77BsmXLgG27yl6yZAn3338/d9xxBwUFBUyZMqVO+x83bhyDBg1i0KBB3Bl1QLV+/XpOPvlkvva1rzFo0KCt3W2MHTt26zHrk7h2l7TVIMwsE7gHOB4oAaab2Xh3n5ewTl/gOuBod//SzLol7OIrdy9IV3w1ZOeQgcPmzeG+VxFJj2Qd4X3nO/CTn8CGDXDSSduWjx4dppUrYdSommWTJ9fr8O7OZZddxnPPPUdubi6PP/44v/jFL3jwwQe36Sq7Y8eOXHzxxfWqdcyYMYO//vWvvPvuu7g7hx9+OEOHDqW4uJju3bvz4osvAqH/p9LSUp555hkWLFiAmaWke+5US2cNYgiwyN2L3X0z8BgwstY6PwLucfcvAdz9izTGs13eOurZccOGOA4vIrvJpk2bmDNnDscffzwFBQXccsstlJSUAKnpKvvNN9/k29/+Nm3atKFt27acdtppTJkyhYMOOoiJEydy7bXXMmXKFDp06ECHDh3Iycnhggsu4Omnn6Z169apPNWUSGcbRA/g04T5EuDwWuv0AzCzt4BM4AZ3fzkqyzGzIqAcuM3dn619ADO7ELgQYN99921woF7V9e+6ddCpU4P3IyI7saNf/K1b77i8a9d61xhqc3cGDhzIO++8s01Zsq6yU6Vfv37MnDmTl156iV/+8pccd9xx/PrXv2batGlMmjSJJ598kj/84Q+8+uqrKTtmKsT9oFwW0BcYBpwF/MnMOkZl+0UdSH0PuNPM+tTe2N0fcPdCdy+sujOhIdZ225/nMk+DFAywISJ7ruzsbFasWLE1QWzZsoW5c+dut6vsdu3asXbt2jrv/5hjjuHZZ59lw4YNrF+/nmeeeYZjjjmGzz77jNatW3POOedw9dVXM3PmTNatW0dZWRknnXQSd9xxB7Nnz07XaTdYOr8RlwI9E+bzomWJSoB33X0L8LGZfUhIGNPdfSmAuxeb2WRgMLA4HYEuO3A4Y3w45XuDpeMAIrJHyMjI4Mknn2TMmDGUlZVRXl7OFVdcQb9+/ZJ2lf3Nb36TUaNG8dxzz/H73/+eY445psb+HnroIZ599tmt81OnTmX06NEMGTIEgB/+8IcMHjyYCRMmcPXVV5ORkUGLFi247777WLt2LSNHjmTjxo24O+PGjdudf4o6SVt332aWBXwIHEdIDNOB77n73IR1RgBnuft5ZtYVeA8oACqBDe6+KVr+DjAysYG7toZ29w1w663w85+HYalzchq0CxFJQt1971n2mO6+3b0cuBSYQHjA4Al3n2tmN5nZqdFqE4BSM5sHvAZc7e6lQH+gyMxmR8tv21Fy2FX5X77HSrqw+YV/p+sQIiKNTlovurv7S8BLtZb9OuG9A1dFU+I6bwMHpTO2RNltW9CFVaxYsWZ3HVJEZI8XdyP1HqFFx3AX05bV6m9DJNWayqiVjV1D/h2UIICWnaIE8eWuDfAtIjXl5ORQWlqqJBEzd6e0tJScejay6r5OILtzSBAVa1SDEEmlvLw8SkpKWLFiRdyhNHs5OTnk5eXVaxslCKBV51Y8zLkM2HsAveMORqQJadGiBb169Yo7DGkgXWIC2rTL4Dwe5uOBp8QdiojIHkMJgjAeBMD6dbpOKiJSRQmCkCDmMoAj7j8v7lBERPYYShCEBFFBJhnrdReTiEgVJQigVStYTxsyvtJdTCIiVZQggIwM+CqjLZkblSBERKooQUQ2ZrUha5MShIhIFT0HEXmt3UjW7LuC78YdiIjIHkIJIjKhx/l8uC9KECIiEV1iinRqX8GWVXUfOUpEpKlTgohc/Pn1PDelE6hTMRERQAmiWus2ZFEBmzfHHYmIyB5BCSKS0S7qb2OdHpYTEQEliK22Joj1utVVRASUILbKbB8SxOYvlSBEREAJYqsN+x/MjfyatVmd4g5FRGSPoAQRqThgADdwI2Wt9o47FBGRPUJaE4SZjTCzhWa2yMzGbmed75jZPDOba2aPJCw/z8w+iqa098Pdvk0Fe/E5az/XJSYREUhjgjCzTOAe4ERgAHCWmQ2otU5f4DrgaHcfCFwRLe8MXA8cDgwBrjeztF772XtDMZ+zDy1ffDqdhxERaTTSWYMYAixy92J33ww8Boystc6PgHvc/UsAd/8iWv4NYKK7r4rKJgIj0hgrrfbuAEB56Zp0HkZEpNFIZ4LoAXyaMF8SLUvUD+hnZm+Z2VQzG1GPbTGzC82syMyKVqxYsUvBtukeJYhVZbu0HxGRpiLuRuosoC8wDDgL+JOZdazrxu7+gLsXunthbm7uLgXSPjebTbTEV6sGISIC6U0QS4GeCfN50bJEJcB4d9/i7h8DHxISRl22Tan27aGMDlCmGoSICKQ3QUwH+ppZLzNrCZwJjK+1zrOE2gNm1pVwyakYmACcYGadosbpE6JlaZOdDTdm3MTM3qen8zAiIo1G2saDcPdyM7uU8MWeCTzo7nPN7CagyN3HU50I5gEVwNXuXgpgZjcTkgzATe6+Kl2xhuPBE50vhs7pPIqISOOR1gGD3P0l4KVay36d8N6Bq6Kp9rYPAg+mM77a9m/9GTklG4D9d+dhRUT2SBpRLsGtq3/MfpOXALPjDkVEJHZx38W0R9nUqgM5m3UXk4gIKEHUUN6qPa236C4mERFQgqihvG0H2lSs0bCjIiIoQdTUoUMYdnTDhrgjERGJnRJEgs8OPpHR/JVyz4w7FBGR2ClBJKgYcBD/x2i+/Con7lBERGKnBJGgW6u1HME7rF6yOu5QRERipwSRYL/Vs3iHo9j81vSdrywi0sQpQSRos0/o8vur5XoWQkRECSJB+7z2AGxaoQQhIqIEkaDDvqEGsWWlHpYTEVGCSNA+rz2VGJWrVscdiohI7NRZXwLLyuT8dv8kv8dAjo07GBGRmClB1PL2PqfzlXraEBHRJabajsqewd6L34w7DBGR2KkGUcsln/+SnPWlwLS4QxERiZVqELVsbtuZdptL4w5DRCR2ShC1lHfoQvvytA5/LSLSKChB1NapM51YzZaNFXFHIiISKyWIWqxrFwBWLf4y5khEROKV1gRhZiPMbKGZLTKzsUnKR5vZCjObFU0/TCirSFg+Pp1xJlp3/Lc5hjdYvqHd7jqkiMgeKW13MZlZJnAPcDxQAkw3s/HuPq/Wqo+7+6VJdvGVuxekK77taT8gjzfJY9kqOHh3H1xEZA+SzhrEEGCRuxe7+2bgMWBkGo+XEvu0LuN7/IP1cz6OOxQRkVilM0H0AD5NmC+JltV2upm9b2ZPmlnPhOU5ZlZkZlPN7FvJDmBmF0brFK1YsSIlQXezFfyDc8ieroflRKR5i7uR+nkg390PBiYC/5dQtp+7FwLfA+40sz61N3b3B9y90N0Lc3NzUxJQm31DI3X5cj0LISLNWzoTxFIgsUaQFy3byt1L3X1TNPtn4NCEsqXRazEwGRicxli3so4dqCCDypV6FkJEmrd0JojpQF8z62VmLYEzgRp3I5nZPgmzpwLzo+WdzCw7et8VOBqo3bidHhkZrM3qRMZqJQgRad7SdheTu5eb2aXABCATeNDd55rZTUCRu48HxpjZqUA5sAoYHW3eH/ijmVUSkthtSe5+Spv12Z1puVaXmESkeTP3ptG3dWFhoRcVFaVkXzeeMYcnX+3MB6XdU7I/EZE9lZnNiNp7txF3I/UeqXLAIOZ+2Z3y8rgjERGJjxJEEgevf4fL/C5Wrow7EhGR+ChBJNH/k5e5gytZvlRVCBFpvpQgkmjZcy8ycFYtTM3DdyIijZESRBLt+uwFQNmHy2OOREQkPnVKEGb2t7osayo6D9gbgHWLlSBEpPmqaw1iYOJM1FProdtZt9FrkRdqEJs+UYIQkeZrhw/Kmdl1wM+BVma2pmoxsBl4IM2xxSc/n1O+9imVLffigrhjERGJyQ5rEO5+q7u3A37n7u2jqZ27d3H363ZTjLtfVhbZffJYsrRF3JGIiMSmrpeYXjCzNgBmdo6ZjTOz/dIYV+zOXHUv/1X8ME3kQXMRkXqra4K4D9hgZl8DfgosBh5OW1R7gKOLH2bUpr9TVhZ3JCIi8ahrgij30GnTSOAP7n4P0KQHbfbcvdiL5Xz66c7XFRFpiuqaINZGDdbnAi+aWQbQpC/QZ/bYi735nJKSuCMREYlHXRPEd4FNwPnu/jlh8J/fpS2qPUCr/fPYiy9YWrxp5yuLiDRBdUoQUVL4B9DBzE4BNrp7k26DaHtgHhVksHrB53GHIiISi7o+Sf0dYBpwBvAd4F0zG5XOwOKWed45HJi/iZmlTfpmLRGR7arriHK/AA5z9y8AzCwXeAV4Ml2Bxa5lS/L3h0WL4g5ERCQedW2DyKhKDpHSemzbOFVU8MvPfkL/+U/HHYmISCzqWoN42cwmAI9G898FXkpPSHuIzEwOL36E9zdmsnr1aXTsGHdAIiK71w5rAWa2v5kd7e5XA38EDo6md2jKfTFFNnXrSR4lLF4cdyQiIrvfzi4T3QmsAXD3p939Kne/CngmKmvSrGeeEoSINFs7SxB7ufsHtRdGy/J3tnMzG2FmC81skZmNTVI+2sxWmNmsaPphQtl5ZvZRNJ1Xh3NJuVb759GTT5UgRKRZ2lkbRMcdlLXa0YbRmBH3AMcDJcB0Mxvv7vNqrfq4u19aa9vOwPVAIeDAjGjbL3cSb0q16JtPeUZLij8sp+7NNSIiTcPOahBFZvaj2gujX/ozdrLtEGCRuxe7+2bgMUJfTnXxDWCiu6+KksJEYEQdt02dX/yCM4/8hA+LlRxEpPnZ2TffFcAzZnY21QmhEGgJfHsn2/YAEru6KwEOT7Le6Wb2deBD4Ep3/3Q72/aovaGZXQhcCLDvvvvuJJyG6d8fnn02LbsWEdmj7WzAoOXufhRwI7Akmm509yOj7jd21fNAvrsfTKgl/F99Nnb3B9y90N0Lc3NzUxBOLWVljH3nVIaufJIVK1K/exGRPVld+2J6zd1/H02v1nHfS4GeCfN50bLE/Za6e1VveH+mepzrnW67W7RtS68PJ3AY05lXu+VERKSJS+fT0NOBvmbWy8xaAmcC4xNXMLN9EmZPBeZH7ycAJ5hZJzPrBJwQLdu9MjOp6JlPHxYrQYhIs5O21ld3LzezSwlf7JnAg+4+18xuAorcfTwwxsxOBcqBVcDoaNtVZnYzIckA3OTuq9IV645kHdCH/ZcU87oShIg0M2m9PcfdX6JWlxzu/uuE99cB121n2weBB9MZX11Y797sb28xb64DFnc4IiK7TdPucC8VCgpY1mUQxXO/ijsSEZHdSgliZ374Q14Y+xZLvmjN5xo7SESaESWIOjjkkPD63nvxxiEisjspQexMZSVHX3kYY7lVCUJEmhUliJ3JyCBrXRlfbzOTmTPjDkZEZPdRgqiL/v0ZmDlfCUJEmhUliLro358e6z/kk4/L+XK39icrIhIfJYi6GDCAzIot9GEx06fvfHURkaZACaIuDjmELad9l0xz3n477mBERHYPDXRQF4MG0eKpx2hZgBKEiDQbqkHUw/DCtUydChUVcUciIpJ+ShB19YMfcOOLhaxdC3Pnxh2MiEj6KUHUVe/etFv+EW1Zy5tvxh2MiEj6KUHU1eDBmDsndJvNq3UdMklEpBFTgqirwYMB+Hav93jtNaisjDkeEZE0U4Koq+7dITeXI7LfY9UqmDUr7oBERNJLCaKuzOD66+n0w1EATJoUczwiImmmBFEfl1xCl3NPYuBA+Ne/4g5GRCS9lCDqo6ICZs3i3GGf8sYbqF8mEWnSlCDqY906OOQQvrf5ISoqVIsQkaZNCaI+OnSAgQPJ++Rt9toLnnsu7oBERNInrQnCzEaY2UIzW2RmY3ew3ulm5mZWGM3nm9lXZjYrmu5PZ5z1cuSR2LtTOfWUSv71L9i8Oe6ARETSI20JwswygXuAE4EBwFlmNiDJeu2Ay4F3axUtdveCaLo4XXHW29e/DqtXc86gWaxdC5Mnxx2QiEh6pLMGMQRY5O7F7r4ZeAwYmWS9m4HbgY1pjCV1jj0WgCM3TKJdO3j88ZjjERFJk3QmiB7ApwnzJdGyrczsEKCnu7+YZPteZvaemb1uZsckO4CZXWhmRWZWtGLFipQFvkPdu8OkSbS47GJGjYJ//hM2bNg9hxYR2Z1ia6Q2swxgHPDTJMXLgH3dfTBwFfCImbWvvZK7P+Duhe5emJubm96AEx17LLRrx7nnwtq1MH787ju0iMjuks4EsRTomTCfFy2r0g4YBEw2syXAEcB4Myt0903uXgrg7jOAxUC/NMZaP6WlcNNNDG07g5494eGH4w5IRCT10pkgpgN9zayXmbUEzgS2/tZ29zJ37+ru+e6eD0wFTnX3IjPLjRq5MbPeQF+gOI2x1k92NvzmN2Q89gjnngsTJsCyZXEHJSKSWmlLEO5eDlwKTADmA0+4+1wzu8nMTt3J5l8H3jezWcCTwMXuvipdsdZb27bhMtP48Zz3faeyEv7yl7iDEhFJLXP3uGNIicLCQi8qKtp9B7z3XrjkEpg/n29cfiAffAD/+Q+0aLH7QhAR2VVmNsPdC5OV6UnqhvrmN8PrM88wZky4xPTUU/GGJCKSSkoQDdWzJwwfDqWlnHgi9OkDd98dd1AiIqmTFXcAjdorr0BGBhnAmDFw+eXw1ltw9NFxByYisutUg9gVGdGfb80aLrgAcnPhxhvjDUlEJFWUIHbVNdfAwIG0aVXJ1VfDxInwzjtxByUisuuUIHbVoYdCSQlMmsRPfgJdu8INN8QdlIjIrlOC2FUjR4ZrS7//PW3awLXXwr//HWoSIiKNmRLErsrJgYsughdegMWLuewy6N0brroKysvjDk5EpOGUIFLhxz+GzEy47z6ys+G3v4U5c+DPf447MBGRhlOCSIXu3eHZZ+FXvwLgtNPCuEI//zksXx5vaCIiDaUEkSonnxzGrAbM4P77Yf16uOKKeMMSEWkoJYhUeustOOIIKC2lf3/45S/hscfg+efjDkxEpP6UIFKpfXuYNg3+93+BcEfTwQfDBReoO3ARaXyUIFLpoIPgzDPhrrtgyRJatoRHH4V16+Dcc6GyMu4ARUTqTgki1W6/PXTBcfnlAAwYEDrxmzQpFImINBZKEKnWsydcf30YqPq114Bwiem73w03Of373zHHJyJSR+rNNR2uuALy8mDoUCDc1fSnP8H8+XDGGaGvpgED4g1RRGRnVINIhxYt4KyzwqWm5cvBnXbtwt1MrVrBKafAihVxBykismNKEOm0YAEccEB4KALYd99w5WnZMhgxAlavjjc8EZEdUYJIp3794Mgjw2hCr78OwJAh8PTT8MEHcOKJsHZtzDGKiGyHEkQ6ZWSE+1z79IHTT4dFi4CQGB5/HKZPDw9gl5XFHKeISBJpTRBmNsLMFprZIjMbu4P1TjczN7PChGXXRdstNLNvpDPOtOrYMfT0CnDccVufmPv2t+GRR0KD9fDh8MUX8YUoIpJM2hKEmWUC9wAnAgOAs8xsm3t3zKwdcDnwbsKyAcCZwEBgBHBvtL/Gaf/9w/2tI0aEEYUi3/lOaJNYsCCMY714cYwxiojUks4axBBgkbsXu/tm4DFgZJL1bgZuBzYmLBsJPObum9z9Y2BRtL/G65BD4I9/DHc4lZTA7NlAuNw0aRKsWgWHHaaBhkRkz5HOBNED+DRhviRatpWZHQL0dPcX67tttP2FZlZkZkUrGtN9oxddBMccAy+/DIR27OnTw6MTI0aErpzcY45RRJq92BqpzSwDGAf8tKH7cPcH3L3Q3Qtzc3NTF1y6PfAA9OoFJ50UBo3YsoXeveHtt8NYEldfHV5Xrow7UBFpztKZIJYCPRPm86JlVdoBg4DJZrYEOAIYHzVU72zbxq1Hj9A6fcEFcOut4YnrZcto2xaeeCLUIF56KfQEq645RCQu6UwQ04G+ZtbLzFoSGp3HVxW6e5m7d3X3fHfPB6YCp7p7UbTemWaWbWa9gL7AtDTGuvu1bh3633j00XA9qVMnAAznpz8NvYZ36gTf+AZcfDF8+WXM8YpIs5O2BOHu5cClwARgPvCEu881s5vM7NSdbDsXeAKYB7wMXOLuFemKNVZnnhmuLeXkhCHojjgC/vIXvjawnKIiuOqqkEcOPLA6l4iI7A7mTeQbp7Cw0IuKiuIOY9cUF4c+nKZNg7594cor4fvfZ+bCNlx0ERQVhbGuf/e78ES2iMiuMrMZ7l6YrExPUu9JeveGqVPhmWfC+NY/+Qn07Mkh3UqYOhXuuy88M3H44aH7cD03ISLppASxpzGDb30r1CLefBMuvBB69CAzEy5eeQv/ueouxo1ZwgsvhMtO558PCxfGHbSINEW6xNRYuIfrS2++CcCWAwcxuc0pXD/nDKZuPoRRo8IY2IceGnOcItKo6BJTU2AGU6aE6sK4cbTo3o3jZ/8vE3/0OGPHwuSXNzKp8BrGHvAMz4z7mI1fNY3ELyLxUQ2iMSsrg02boFs31k6ZRevhh5NZsRmANdae0u4Hwc230OsHw2DNmtAj4H77he4+RERQDaLp6tABunUDoN0xBWSuK8Pffof5V/yRt3qdS8nSDL53fjaHHALPj5kY7oxq1So0hh9/fGjAKC4O+1q6NDSQf/IJbNig+2lFRDWIpmz58jDuxN/+BsuLPuF4m8TQvMUM6bqY/MpiclYuDT0FHnAA3HVXGEu7SnY2dO4cGsvz8sKdVePHh2Xt2kGbNtC2bUgy2dlhrIvly8OyNm3ClJ0dnvYzi+1vICI7tqMahBJEM7FgQRh/4tlnw2h2ELryGDkydBA4pHsJWfPeh88+g9LS0L3sqlUwblxICHfeGd6vWhUe6KuyYUOolVx+Odx9d82DZmRARfR8449+BH//O7RsGRJHdjbk5sLMmaH8V78Ko+5lZkJWVnjde2946KFQ/j//EwKvKsvKConrhhtC+R/+AP/5T3V5ZmYY4/WCC0L5Qw+F88rIqC7fb78wQDjAk0+Gc8nMrF6nZ8/QkyKEbnbLy6vLMjKge/dwKxmE3hbNau6/SxfYZ59QG1uypOa2mZnVSdYd1q2ruW1GRpiUXCXNlCCkhsWL4bnnQrJ4883w/dS+PQwbFq48HX98GC11u99NlZXhy3TdOthrr7DiokXw8cdh2bp1IYmUl8Oll4ZtnnwyfIlu2hSmzZtDsrjvvlB+440weXJIKOXl4bVbN3j++VB+wQWhkT6xfP/9wzYQBmN6553q8srK8OX+9tuh/KCDYM6cmudxwgkwYUJ4n58fEkyi006Dp54K77t0Cckx0XnnVSewli1hy5aa5ZdcEhLXpk3hSfnaxo4NfXGVltYYJ2SrW26BX/wixHXAATWTS2Ym3HZbSLwLFoR/tNrlt94aRqaaPRt+8IOa5RkZYf/DhsGMGaHTyNrl118PBQWhFnnXXTWTV2ZmuG2uT59Q/sgj1eVV64wZEz4f06eHBFs7AZ5/fvjgvfdeeAq0dgI9/fTwd5s7Fz76aNvy444Lr4sXw+ef19x/ZmaIHcKPnrVrax67RYuQ4CG0z5WX1yzPygr/ps3AjhJE1u4ORuLXp0/owuOqq8J302uvhf+/EyeGq0gQfvgedVQYyOjoo8P/ta3/XzIywi/ftm2rd7r//mHanlGjwrQ9118fpu35y192fFKTJtWcd6/ZjvLuuyF5JE5ZCR//KVNC0qqsrC5PPL+JE0MCqKioXidq/wFCxk3cd2VlaOuBcJyHHqq5bWUlDB4cylu1Cj001t7+618P5e3ahRpaYmyVlSGLQ6iJHH98zfKKinA5EMKXYY8eNY9dURG+DCGcV1nZtuUbNoTyVatq/v2qyi+6KJR/9BH89a/bln/veyFBvPNOSHS1nXZaSBAvvQS//OW25SNGhATxt7/B7bdvW75pUziHcePg3ntrlrVsGcohJOK//a1meZcu1d0ljx4dLqEmys8PP3gg/JB49dXqmmtWVvjBEd1yzre+FZJwYvkhh8DDD4fyc8+tWbvNyoLCQrj55lB+2WWhs7XE7QsLQ/KH8P9i8+aa2xcUVNd+77knPC+VhptPVIOQGoqLw3fhG2+EH99LloTlOTlhQKMjjgif/cGDQ5t3hm5zkJ2prKyu9SUmkPbtwxfe2rXhV3ztBNq7dyhftiy0b9UuP/LIUHtdsCDcXJFYBvDNb4bXqVPDBztx+xYtwhc3wIsvhhpwYnm7dqEnAwjJ/aOPquMvLw+Jb2w0ivLNN4fty8urz7Nfv3BZFELtt+r4VeWHH159SXbYsDCIWFVZeXkYrP7Pfw7l3buHX3JVNWMIta+qH02ZmSGZZ2c36J9Hl5ikwT77LCSKt9+Gt96CWbPCjxkIP1wLCkKyGDw4/Kg68MDwf0tE0sA9JBH36hpDaWmoLTawvUoJQlJm82aYNy9cNq6aZs0KzQ5VevaE/v1hwIDw2r9/SBxdu6rNVWRPowQhaVVZGWrYc+fC/Plhmjcv1PyrLmNDqFn07h3aQBJfe/fW83sicVEjtaRVRka45NqvX7hppkplZbg0PH8+fPhhuNmkuDgkjxdfrG5DrNpH9+7hztW8vFALSXzNywsN51n6xIrsNvrvJmmTkRFuBsnPhxNPrFlWWRnaN6qSxuLFoZ2upATefz8kkK++2nZ/e+8d2gd3NHXrFi5nVd2kIyINowQhscjIqK4ZDB26bbk7rF4dEsann1Ynj5KScEPL8uXhsYYvvqhuNK+9/65dw92MnTtXT4nzycratlU7iUgVJQjZI5mFXjo6dQp3R22Pe7iFvyppJE5ffFH9QPgnn4TG9NoPgteWmRnuvuzQIbwmvk+2rPb7ql5G2rTR5TBp/PQRlkbNDDp2DNMBB9Rtm40bw3NJq1bV7FWktDQsX7MmTGVl4XXZstDgXrUsWY0lmezsmgljR1NiF1atW4fnTlq1qvma7H12ti6lSfooQUizk5MTGrz32adh22/aVDOBJL5fv377U1UPJF98sW1ZYoN9fbVoseMkUvU+Ozs8YJxsakjZjrapeiBYl+saNyUIkXqq6mcwNzd1+ywvD7cEJyaMr74KtZ2NG3ftfWlpeN28ueZU1SXWpk3p6929qmeIFi2qk8auvK/PNondMtXuJmp7ZTubUr3tnt4TQVoThJmNAO4CMoE/u/tttcovBi4BKoB1wIXuPs/M8oH5QNVoy1Pd/eJ0xioSp6ys6naMOFRUJE8eyaa6lFX1OlFeHrp6asj7DRvqv21ibxSNRe0EUtWRb9VUe1my+YICePTR1MeWtgRhZpnAPcDxQAkw3czGu/u8hNUecff7o/VPBcYBI6Kyxe5ekK74RKRaZma4HNWqVdyR7LrKyup+FZNNtfs0rM/U0G3rsl1lZc2pLstq9wuZaumsQQwBFrl7MYCZPQaMBLYmCHdfk7B+G6BpPNYtIrHJyGhwv3VSSzqvgPUAPk2YL4mW1WBml5jZYuC3wJiEol5m9p6ZvW5mxyQ7gJldaGZFZla0YsWKVMYuItLsxd5E4u73uHsf4FqgqlP4ZcC+7j4YuAp4xMy2uTrr7g+4e6G7F+amssVQRETSmiCWAj0T5vOiZdvzGPAtAHff5O6l0fsZwGKgX3rCFBGRZNKZIKYDfc2sl5m1BM4ExieuYGZ9E2ZPBj6KludGjdyYWW+gL1CcxlhFRKSWtDVSu3u5mV0KTCDc5vqgu881s5uAIncfD1xqZv8NbAG+BM6LNv86cJOZbQEqgYvdfdW2RxERkXTReBAiIs3YjsaDiL2RWkRE9kxKECIiklSTucRkZiuA/+zCLroCK1MUTmOhc24edM7NQ0PPeT93T/qcQJNJELvKzIq2dx2uqdI5Nw865+YhHeesS0wiIpKUEoSIiCSlBFHtgbgDiIHOuXnQOTcPKT9ntUGIiEhSqkGIiEhSShAiIpJUs08QZjbCzBaa2SIzGxt3PKliZg+a2RdmNidhWWczm2hmH0WvnaLlZmZ3R3+D983skPgibzgz62lmr5nZPDOba2aXR8ub7HmbWY6ZTTOz2dE53xgt72Vm70bn9njUYSZmlh3NL4rK82M9gV1gZpnRmDEvRPNN+pzNbImZfWBms8ysKFqW1s92s04QCcOinggMAM4yswHxRpUyD1E9fGuVscAkd+8LTIrmIZx/32i6ELhvN8WYauXAT919AHAEcEn079mUz3sTcKy7fw0oAEaY2RHA7cAd7r4/oSPMC6L1LwC+jJbfEa3XWF1OGLu+SnM45+HuXpDwvEN6P9vu3mwn4EhgQsL8dcB1cceVwvPLB+YkzC8E9one7wMsjN7/ETgr2XqNeQKeI4yJ3izOG2gNzAQOJzxRmxUt3/o5J/SufGT0Pitaz+KOvQHnmhd9IR4LvABYMzjnJUDXWsvS+tlu1jUI6jgsahOyl7svi95/DuwVvW9yf4foMsJg4F2a+HlHl1pmAV8AEwkDbK129/JolcTz2nrOUXkZ0GW3BpwadwLXEIYDgHAOTf2cHfi3mc0wswujZWn9bKdtPAjZs7m7m1mTvMfZzNoCTwFXuPsaM9ta1hTP290rgAIz6wg8AxwYb0TpZWanAF+4+wwzGxZzOLvTf7n7UjPrBkw0swWJhen4bDf3GkR9h0Vt7Jab2T4A0esX0fIm83cwsxaE5PAPd386WtzkzxvA3VcDrxEur3Q0s6ofgInntfWco/IOQOnujXSXHQ2camZLCEMVHwvcRdM+Z9x9afT6BeGHwBDS/Nlu7glip8OiNjHjqR617zzCNfqq5d+P7nw4AihLqLY2GhaqCn8B5rv7uISiJnveFobn7Ri9b0Voc5lPSBSjotVqn3PV32IU8KpHF6kbC3e/zt3z3D2f8H/2VXc/myZ8zmbWxszaVb0HTgDmkO7PdtwNL3FPwEnAh4Trtr+IO54UntejwDLCcK4lhDs5uhAa9j4CXgE6R+sa4W6uxcAHQGHc8TfwnP+LcJ32fWBWNJ3UlM8bOBh4LzrnOcCvo+W9gWnAIuCfQHa0PCeaXxSV9477HHbx/IcBLzT1c47ObXY0za36rkr3Z1tdbYiISFLN/RKTiIhshxKEiIgkpQQhIiJJKUGIiEhSShAiIpKUEoQ0CmbmZvb/EuZ/ZmY3pGjfD5nZqJ2vucvHOcPM5pvZa7WW51vU666ZFZjZSSk8Zkcz+0nCfHczezJV+5emTQlCGotNwGlm1jXuQBIlPLlbFxcAP3L34TtYp4Dw7EaqYugIbE0Q7v6Zu6c9GUrToAQhjUU5YczdK2sX1K4BmNm66HWYmb1uZs+ZWbGZ3WZmZ1sYP+EDM+uTsJv/NrMiM/sw6uunqhO835nZ9KhP/YsS9jvFzMYD85LEc1a0/zlmdnu07NeEB/n+Yma/S3aC0dP8NwHfjfr8/270BO2DUczvmdnIaN3RZjbezF4FJplZWzObZGYzo2OPjHZ7G9An2t/vatVWcszsr9H675nZ8IR9P21mL1sYZ+C3df5XkiZFnfVJY3IP8H49v7C+BvQHVgHFwJ/dfYiFwYQuA66I1ssn9G3TB3jNzPYHvk/oouAwM8sG3jKzf0frHwIMcvePEw9mZt0J4w0cShiT4N9m9i13v8nMjgV+5u5FyQJ1981RIil090uj/f0PoWuI86MuNaaZ2SsJMRzs7quiWsS3PXRO2BWYGiWwsVGcBdH+8hMOeUk4rB9kZgdGsfaLygoIveFuAhaa2e/dPbF3UGkGVIOQRsPd1wAPA2Pqsdl0d1/m7psI3Q5UfcF/QEgKVZ5w90p3/4iQSA4k9HfzfQtdab9L6Nagb7T+tNrJIXIYMNndV3joWvofwNfrEW9tJwBjoxgmE7qN2Dcqm+juq6L3BvyPmb1P6HKhB9VdP2/PfwF/B3D3BcB/gKoEMcndy9x9I6GWtN8unIM0UqpBSGNzJ2FQnL8mLCsn+rFjZhlAy4SyTQnvKxPmK6n5+a/d54wTvnQvc/cJiQUWuphe35DgG8CA0919Ya0YDq8Vw9lALnCou2+x0NNpzi4cN/HvVoG+K5ol1SCkUYl+MT9B9XCSEEbaOjR6fyrQogG7PsPMMqJ2id6EEbgmAD+20IU4ZtYv6klzR6YBQ82sq4Uhbc8CXq9HHGuBdgnzE4DLzMKgFmY2eDvbdSCMkbAlakuo+sVfe3+JphASC9GlpX0J5y0CKEFI4/T/gMS7mf5E+FKeTRgLoSG/7j8hfLn/C7g4urTyZ8LllZlRw+4f2ckvaQ9dKo8ldD09G5jh7s/taJtaXgMGVDVSAzcTEt77ZjY3mk/mH0ChmX1AaDtZEMVTSmg7mZOkcfxeICPa5nFgdHQpTgRAvbmKiEhyqkGIiEhSShAiIpKUEoSIiCSlBCEiIkkpQYiISFJKECIikpQShIiIJPX/AbYLhtszaVJqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#繪製損失曲線\n",
    "loss_history_test = np.zeros(iterations)\n",
    "for i in range(iterations):\n",
    "    loss_history_test[i] = loss_function(X_test,y_test,weight_history[i],bias_history[i])\n",
    "index = np.arange(0,iterations,1)\n",
    "plt.plot(index,loss_history,c='blue',linestyle = 'solid')\n",
    "plt.plot(index,loss_history_test,c='red',linestyle = 'dashed')\n",
    "plt.legend(['Training Loss','Test Loss'])\n",
    "plt.xlabel('Number of Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28431d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression testing accuracy: 86.89% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linnn\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#跟上面作法類似，直接使用人家寫好的model，\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)   #fit直接包含了gradient descent\n",
    "print('Logistic regression testing accuracy: {:.2f}% '.format(lr.score(X_test,y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e212503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用dummy variable解決 各類別裡面的資料關係，有些欄位裡面編號0,1,2,3.. 並非代表大小關係，而是有各自含意，把他們拉出來，變成各別ㄉ欄位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "218dd469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "      <th>thal_0</th>\n",
       "      <th>thal_1</th>\n",
       "      <th>thal_2</th>\n",
       "      <th>thal_3</th>\n",
       "      <th>slope_0</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  ca  ...  \\\n",
       "0   63    1       145   233    1        0      150      0      2.3   0  ...   \n",
       "1   37    1       130   250    0        1      187      0      3.5   0  ...   \n",
       "2   41    0       130   204    0        0      172      0      1.4   0  ...   \n",
       "3   56    1       120   236    0        1      178      0      0.8   0  ...   \n",
       "4   57    0       120   354    0        1      163      1      0.6   0  ...   \n",
       "\n",
       "   cp_1  cp_2  cp_3  thal_0  thal_1  thal_2  thal_3  slope_0  slope_1  slope_2  \n",
       "0     0     0     1       0       1       0       0        1        0        0  \n",
       "1     0     1     0       0       0       1       0        1        0        0  \n",
       "2     1     0     0       0       0       1       0        0        0        1  \n",
       "3     1     0     0       0       0       1       0        0        0        1  \n",
       "4     0     0     0       0       0       1       0        0        0        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.get_dummies(df['cp'],prefix = 'cp')\n",
    "b = pd.get_dummies(df['thal'],prefix = 'thal')\n",
    "c = pd.get_dummies(df['slope'],prefix = 'slope')\n",
    "\n",
    "frames = [df,a,b,c]\n",
    "df = pd.concat(frames,axis = 1)\n",
    "df = df.drop(columns = ['cp','thal','slope'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "613c7936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression testing accuracy: 85.25% \n"
     ]
    }
   ],
   "source": [
    "#準確率提高\n",
    "y_pred = predict(X_test,weight_history[-1],bias_history[-1])\n",
    "testing_acc = 100 - np.mean(np.abs(y_pred - y_test)) * 100\n",
    "print('Logistic regression testing accuracy: {:.2f}% '.format(testing_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442521b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
